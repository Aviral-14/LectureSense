{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9604143,"sourceType":"datasetVersion","datasetId":5859615},{"sourceId":9604166,"sourceType":"datasetVersion","datasetId":5859629},{"sourceId":9608906,"sourceType":"datasetVersion","datasetId":5863000}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install --upgrade transformers datasets[audio] accelerate\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T18:56:14.883041Z","iopub.execute_input":"2024-10-11T18:56:14.883487Z","iopub.status.idle":"2024-10-11T18:57:08.473063Z","shell.execute_reply.started":"2024-10-11T18:56:14.883439Z","shell.execute_reply":"2024-10-11T18:57:08.471672Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (24.0)\nCollecting pip\n  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-24.2-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.0\n    Uninstalling pip-24.0:\n      Successfully uninstalled pip-24.0\nSuccessfully installed pip-24.2\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nCollecting transformers\n  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nCollecting accelerate\n  Downloading accelerate-1.0.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: datasets[audio] in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (2.2.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets[audio]) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.9.5)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.12.1)\nRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.10.2.post1)\nRequirement already satisfied: soxr>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.5.0.post1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0+cpu)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.14.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.60.0)\nRequirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.8.2)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.0.8)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2024.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.22)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.43.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa->datasets[audio]) (3.11.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-1.0.0-py3-none-any.whl (330 kB)\nInstalling collected packages: accelerate, transformers\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.34.2\n    Uninstalling accelerate-0.34.2:\n      Successfully uninstalled accelerate-0.34.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.45.1\n    Uninstalling transformers-4.45.1:\n      Successfully uninstalled transformers-4.45.1\nSuccessfully installed accelerate-1.0.0 transformers-4.45.2\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\nimport librosa\n\n# Set up device and data type\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n\n# Load the model\nmodel_id = \"openai/whisper-large-v3-turbo\"\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\n    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n)\nmodel.to(device)\n\n# Load the processor\nprocessor = AutoProcessor.from_pretrained(model_id)\n\n# Create the pipeline\npipe = pipeline(\n    \"automatic-speech-recognition\",\n    model=model,\n    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n    chunk_length_s=30,  # Process 30-second chunks\n    batch_size=8,  # Adjust based on your GPU memory\n    torch_dtype=torch_dtype,\n    device=device,\n)\n\n# Load your audio file\naudio_path = \"/kaggle/input/audio-file/output_audio.wav\"  # Replace with your audio file path\naudio, sr = librosa.load(audio_path, sr=16000)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T19:08:39.292870Z","iopub.execute_input":"2024-10-11T19:08:39.293886Z","iopub.status.idle":"2024-10-11T19:09:05.745146Z","shell.execute_reply.started":"2024-10-11T19:08:39.293828Z","shell.execute_reply":"2024-10-11T19:09:05.744315Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.62G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb5e7c3a224843e59a41bf9855fa22f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c9c1834636d4f1abf57942f4ab4c329"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3ad1f8027e14ee18c17c2f63120d9c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddf3220ea5454abc9c074156d7afcb3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fc9185581bc40febb35cb6099e24a92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.71M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b220e2d7a289401e91af027a304ab017"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25155903f25c40dc8deca89151edc7be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d88a5b0d630463b8291010cdec06ee2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ad56c85a77744dfaafdf5217dc017d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b25b10cd8aca46f18c6facfea508bfb3"}},"metadata":{}}]},{"cell_type":"code","source":"\naudio_path = \"/kaggle/input/lecture/lecture_audio.wav\"  \naudio, sr = librosa.load(audio_path, sr=16000)\nresult = pipe(audio, generate_kwargs={\"language\": \"english\"})  \n\nprint(result[\"text\"])\n\n\nwith open(\"transcription.txt\", \"w\") as f:\n    f.write(result[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-11T19:15:58.602709Z","iopub.execute_input":"2024-10-11T19:15:58.603480Z","iopub.status.idle":"2024-10-11T19:17:00.546775Z","shell.execute_reply.started":"2024-10-11T19:15:58.603436Z","shell.execute_reply":"2024-10-11T19:17:00.545752Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":" Screen also visible now? Yes ma'am. Thank you. Let us start with the next part that is statistical inference. We will learn upon test of significance and from here we will learn about three tests that is chi-square test, t-test and f-test. But before that we have to learn about what is this test of significance. What do we mean by statistical inference? What is the importance of statistical inference in design of experiments? And then we will come to the type of hypothesis. And then we will start upon the different tests we have set. So statistical inference is to deduce, right? Is to infer whether the decision you are making upon a hypothesis is correct or not. Whenever you have your design of experiments, whenever you do experimentation at the end of your design, then you have your framework which has been built using different components, now you have different settings as well. And now for for these settings you will decide to test whether whatever assumptions you have started with whatever system model you have begin with is validated or not right is it correct or not the decision you are taking the optimal solutions you have proposed have been aligned with your hypothesis or not whether you are able to actually handle the problem you have started with right so we have to at least have few statistical inferences few deductions from our work so that we can say we have validated and we have proved the hypothesis that we have started with right so the problem here is to learn or we have to overcome the uncertainties because whenever we start with any like hypothesis whenever we start with a research problem there are a lot of uncertainties there are a lot of risk which are involved in any research problem right so we are not aware whether this framework which we are proposing whether this flow of work which have proposed, whether the design which we have come up with is going to actually map with the hypothesis we have proposed or is going to validate the results as well. Because at the end of the day, you have to validate, you have to defend based upon your experimentation, based upon your validations, you can prove that your hypothesis which you have started with has been correctly proved and it has been accepted as well, right, by mass and then you can publish your results. Now we have to learn these uncertainties with time and we have to overcome as well, right, whatever comes within the decision-making process. This statistical inference uses the probability concept. So till now we have learned all about the probability theorems which started with the priority theory coming to the posterior and then Bayes theorem Bernoulli distributions. We have come to different binomial Poisson and normal distribution. We have seen how we can use the concept of probability and we can see how we can test a sample from a population. And then based upon our test, we can say that this is what we have come with or this is the difference between the expected or the actual results. Right. So what has to be there and what out to be there. Right. What is there and what out to be there. That difference we have already come up with the conditional probabilities and the other theorems. So, in statistical inference as well, we are going to use the probability concept. So, basically, this SI uses the probability concept and it will tell you that how we can deal with the uncertainties, right? And then we can say after using the statistical inferences and using this probability, we can say that whether the hypothesis is correct, accepted or rejected also. So it's simply the process of selecting and using a sample statistics. So you can use this SI or you can call this SI as the process of selecting and using sample statistics. So, you have to apply some sample statistics and by applying the sample statistics, you can actually draw the inference because this complete test of significance is based upon the inference from the sample population and you can draw the inference about a population parameter. So, we have to always keep in mind that an exhaustive experimentation would not be possible for each and every kind of problem we have taken up, right? So, might not be possible that I test everything. Say I have a data set of say 10 lakh images or so. I might not be able to test on or validate on all the 10 lakh images or so because an image might contain 100 parameters. So 10 lakh into 100, you can imagine the scope, right? You can imagine the range of the experimentation. So this might require a high computational resource as well at the backend to process this much of data set, right? So in that case, we have always said that from the complete population, we are going to pick some sample and we can test the sample. And when we test the sample, we can say that the sample is the representation of my complete population and if my sample has been accepted if my sample has proved correct for the hypothesis my hypothesis has been accepted for that selected sample so I can say that I have a better representation of my population as well right but yeah this yeah, this is also true in experimentations. We should keep increasing the sample size as well so that we can actually see the deviations. If there is an actual deviation from your sample mean towards your population mean, then if there is a large, like significant gap in the mean of your sample or your population, then your hypothesis might not be accepted at the later stages. So you have to take care of that as well. But as I said, exhaustive experimentations might not be possible sometimes. So we always go for the sample frames and we test or we infer based upon these sample frames and then we present the complete population. So we said we will draw an inference about a population parameter. And this population parameter is nothing. It is the subset of this, right, based on subset of it. So this is my statistical inference, which is process of selecting and using sample statistics to draw inference about any population parameter which is based on subset of that population. Now we have two classes of problems. When we said the problem is to overcome or learn the uncertainties. So we have these two classes of problems we call the first class as hypothesis and we call the second class as estimation right so hypothesis testing basically so hypothesis testing so we have an. Because hypothesis, we already know that it is a simple assumption we start with into the research problem. Right. So this is a simple assumption. And this assumption is about some parameter from the population. So we have population and we will take one parameter or something and then we will on the characteristics we will make some assumptions. Right. Now, please mute yourself. All of you. Hypothesis testing is used to test the hypothesis about parent population as I already said. So we will use this hypothesis testing for testing of the parent population from which your sample has been drawn. So you have to take care whatever population you have considered for your validation for your inferences only from that population you are trying to draw some sample? So it is basically to infer the result of hypothesis which is performed on sample which has been drawn from a large population, right? So this is hypothesis testing. So I hope you understand this hierarchy. We have population and then we will have this sample from the population and from this sample we will have some statistics. As we already said, it is the process of selecting and using a sample statistics, right? And the statistics would be from some parameter only. Right? And based upon that, we will finally see the, or we will validate or we will check which parameters they have been. They have this significance level or so. So we will learn this one by one. Now estimation. The second class is estimation. Now what is estimation?, estimation is to use the statistics obtained from the sample again, whatever sample you have selected obtained from the sample or we can call this as the estimate of unknown parameter of population. Again, the parameter of population will be from the same population from where we have drawn that parameter from which the parameter has been drawn. So, it's nothing. Estimation is just, estimate is what? Estimate is a rough calculation of some value, of some number, of some quantity, right? So we can use some statistics, right, which has been obtained from the sample, which we have taken from a population. And it could be the rough number or rough calculation of any quantity or value from which your parameter has been drawn. So we are going to estimate, we are going to perform this estimation. So this is another class, but basically we are going to work upon the hypothesis testing only. So estimation is just to estimate, have rough calculations of the numbers and quantities, right, of unknown parameters. So you have selected some parameter and based upon that selection, based upon the statistics for that particular sample from the population, you are going to work on the unknown parameters of your population so that is another class right that is another problem we can say but for now we will focus upon hypothesis testing because the test of significance is completely going to be relied upon this and we will learn upon this in detail. Now hypothesis testing, it begins with an assumption model as we said. It begins with an assumption and we call this assumption as hypothesis. And this is always about a population parameter. So, this is again repetition, but what we have learned, hypothesis begins with an assumption. The testing hypothesis begins with an assumption, which is known as hypothesis about a population parameter. Now, it is nothing. We have already called it as assumption. So, this is a supposition basically. And this supposition has been made as a basis for what? We are going to do reasoning. We have to answer some questions. We have to formulate the hypothesis. And based upon the formulation of that hypothesis, we have to answer whether the hypothesis is going to be accepted or it is going to be rejected. Now, if we see a very technical definition in literature, you will find that there is a scientist, Maurice Hamburg, who stated that a hypothesis in statistics specifically is simply a quantitative statement about a population. So, in hypothesis and specifically in statistics when we learn this so we can say that this is a quantitative statement about any population and there are three sorry five major steps when we work and when we start upon the assumptions or the suppositions or we start with the research problem. So, first step is to set up a hypothesis. So, we set up the hypothesis. At the second step, we set up a suitable significance level. So we have to decide upon this significance level. What will be the significance level that I am going to get into detail after this. And then we have a testing criteria. We have to set a test criteria after that. Once we have decided upon a suitable significance level. So we will do some, we can have an analysis plan which can have some like threshold or cut lines that how data will be evaluated, right? So we can set up a test criteria based upon our problem again. So we will have these these cut lines we will have some threshold that how my data is going to be evaluated and different problems different domains will have different test criteria of course and at the fourth step we will do some computations and fifth step is to make the decision so basically we said when we start with the hypothesis testing, we will first set up a hypothesis and then we will have this suitable significance level and then we will set up a test criteria and after that we will do some computations and then we will have the decision out of that hypothesis. So, whatever decision we are going to make, then we have to defend that this decision has been an optimal decision as per the assumptions we have set or we have started with. Now, let us start with the first step that is we have to set up a hypothesis which is very, very important when we have to start with this hypothesis testing. Now, when we have to set up a hypothesis which is very very important when we have to start with this hypothesis testing. Now when we have to set this hypothesis we have two categories here. What are these two categories? First category is a null hypothesis which is denoted by H0. You might get different nomenclature as well in literature, so you can go with any nomenclature, but it has to be a standard nomenclature again. And then we have alternate hypothesis. So it is denoted by H of A. Now, what is this null hypothesis? So it's again a very useful tool when you test the significance of difference. So whatever we have said till now, all this process has to be learned or this process has to be applied in order to test the significance of difference right test the significance of difference how much difference is there again i will repeat when you have say some sample and you assume the mean of that sample which we call as hypothesized mean right so and we will calculate the actual mean so we have an assumed mean and we have a calculated mean and then then we will see what is the difference right how much is that difference between the actual and the calculated or the assumed mean of that sample or that population right so we have to test that difference and based that difference, based upon the level of that difference, we will decide whether the hypothesis is going to be categorized as a correct or accepted hypothesis, or it will be incorrect or a rejected hypothesis, right? So whatever we have said is to test the significance of this difference, right? So as I said, suppose you have a sample. There is a sample and you assume mean of that sample. And this assumed mean is always known as in literature we call this as hypothesized mean. Because this is a hypothesis, this is simply a supposition or an assumption. So we say this as hypothesized mean. And then in the next step you will calculate the mean and now you will see how much is the difference how much is the difference between the two. So, we try to conclude that lower is the difference. As low as the difference is, right? More is the probability. More is the probability that the hypothesis you have chosen is correct. So, which means that the assumed mean, the hypothesized mean is comparable to the calculated mean. So when this is comparable, it means whatever sample we have selected and whatever hypothesized mean we have calculated for that sample. So we said that and after that the calculation of the actual mean for that sample or the population and the difference is very, very low. It means they are comparable and whatever hypothesis we have selected is going to be actually accepted right and then we can say that the hypothesis is correct which we have chosen right and the assertion or the basic meaning from here is that there is no real difference in the sample and the population so it asserts that the assertion which comes from this is there is no much difference in the sample and the population which means it is invalid or void or amounting to nothing and we can say that hypothesis is correct and it can be accepted. Now let us take one example. So understand we are learning null hypothesis right. So let's take one example. You have to check whether coaching centers they are benefiting the students or not they are benefiting the students right so now we have to start so this is my problem i have to look for uncertainties for that i have to start i have to do some hypothesis testing which is the first class of the problem. And with the first step of that, we will start with setting up a hypothesis. And into setting up of hypothesis, we said there are two categories, which is null hypothesis and alternate hypothesis. And now we have started with null hypothesis. So understand that sequence and let's formulate the hypothesis. So what will be the null hypothesis here? Null hypothesis says that I will start with the supposition or presumption or my assumption that extra coaching not benefiting the students. So, this will actually become my null hypothesis. I said extra coaching not benefiting the students. So, whenever we do this statistical test, so null hypothesis are meant to be rejected, right? So, you have to, because if we say that this is rejected, that extra coaching is not benefiting the students and we have rejected this. So actually we have accepted the alternate hypothesis of this, right? And what is this alternate hypothesis? So generally when we start with the assumptions or when we start the hypothesis testing, we try to formulate null hypothesis. What is alternate hypothesis? So it is going to specify only those values that you or the researcher believes to hold true. And of course, we hope that the sample data leads to the acceptance of this hypothesis as true, right? The hope is that the sample data leads to acceptance of this hypothesis as true. So, we have this alternate hypothesis, right? So, we can formulate both hypotheses for the problem. For example, again let's take one example. There is a psychologist. And he wants to test whether particular class. I am just giving you the examples to formulate the hypothesis so that whenever you will get any problem for test of significance you have to start with this hypothesis formulation and you have to prove accordingly if you have come up with null hypothesis then based upon the test of significance you have applied chi f or t test you have to prove whether this is going to be accepted or rejected, right? And into which window it is going to be, it is going to fall, right? And then you have to formulate the hypothesis. You have to start with this. So whether particular class have mean IQ higher than 100, right? So this is again, I have started with some problem. So I have a problem. Now I'll with the hypothesis formulation. So, what will be the null hypothesis or we will denote it more formally which is H naught which says that say mean is denoted by mu in standard statistics. So, null hypothesis will say that mu or mean is not equal to 100, right? Mean IQ is not equal to 100. So, we will start with this null hypothesis and we will see, right, whether it is going to fall according to the test of significance or not. And what will be the alternate hypothesis? As I said, we can formulate both hypotheses, right, for the problem. So, this could be mean iq is equal to 100 so if it is alternate it could be equal to or greater than 100 that is true yes so i'm just giving you a simple example so that will depend upon the type of problem you have so i'll give you one example for that greater than or equal to will come to that example as well so suppose you have to write hypothesis for mean iq of different classes right so you will have two mean again for different class same mean one for the first class and mean for the second class and then you have to have their difference as well. You have to define the difference. So how you are going to write this? So you will have your null hypothesis as the difference of mean IQ of both the classes which is not equal to 100 and then you will have an alternate hypothesis which is difference of these two classes mean IQ of these two classes which is equal to 100. So, this is just an example of simple formulation of null and alternate hypothesis. Obviously, these expressions will vary depending upon the type of problem. It could be greater than, less than, equal to, right? And whatever you have chosen, the parameters, depending upon that, you will do, right? So, conventional approach is not going to construct a single hypothesis, I mean to say, about a population parameter. But it could rather can be used to set up two different hypotheses right. So generally we try to formulate two hypotheses from for the same problem right and any for any population parameter so that one of the hypotheses can act as a backup as well right. If one is rejected so we can say the could be accepted. So, that is a conventional approach we can go with in research, right? Or in statistical inference when we are doing the hypothesis testing or so, right? And as I already said, you have to make note that when you increase the population, right? Or your sample size. So, what actually you are doing. By using or doing this. By increasing the population. Or the sample size. You are actually controlling the errors. So it is done to control the errors. Because you cannot avoid the errors. So it is not good always to do experimentation on a very, very small scale as well. And exhaustive is sometimes not possible for your research problem. So we have to take care that we have a validated or we have a standard test data set and test data size as well so that we can defend that hypothesis which we have said is proved, has proved correct, right? And it has been accepted. So you can slowly increase the population or the sample size and you can control the error. So the type of errors you can see in your hypothesis and then you can control the type of errors in your hypothesis now when it comes to error so there is a new keyword that is error we have to learn about these types of errors now what kind of errors we have in hypothesis right so we have Two types of error. Which are major errors. And then the other two. Formulations will give you the correct decision. So we will learn about four formulations. Upon hypothesis testing. The first formulation says that. If. Hypothesis is true. And whatever test you have applied has rejected it. So this leads to type 1 error. And in literature it is denoted by alpha. The second formulation says that if hypothesis is false and test accepted. It means because you said hypothesis is false and your test has accepted the false hypothesis. And in the first case there is false rejection of your null hypothesis. So we assume that this is null hypothesis which we are talking about. So it is going to lead to error which is known as type 2 error. And which is denoted by beta. The third formulation says that. If. Hypothesis is true. And test accepted. It means we have done a correct decision. Or we have done the correct assumptions upon the hypothesis, the assumed or the supposed hypothesis is correct. And if hypothesis is false and test also reject that hypothesis, again, it implies that we have a correct formulation of hypothesis, right? So, basically we said we have these four formulations under type of errors where we will have type 1 error alpha, type 2 error beta based upon the false or the true rejection of your null hypothesis and then there is correct decision based upon when your hypothesis is also correct and test also accept and hypothesis if it is incorrect test also reject that hypothesis. You will find that alpha is we can say probability of type 1 error where you said rejecting null hypothesis, false rejection as I said. So you do reject the null hypothesis and beta which is type 2 error. So this is actually accepting null hypothesis. And alpha is 1 minus beta. Or we can say that correct decisions, they are denoted by 1 minus alpha or 1 minus beta. So, you can draw a matrix here. For example, you can have this accept and reject region. And then depending upon the hypothesis, If it is true. It will be 1 minus alpha. So your hypothesis is true. And the test also accept. It means you have done a correct decision. Which is represented by 1 minus alpha here. And then. If your hypothesis is false. And your test also accept. So this will give you an error which is the second error. Type 2 error. Or what we will do we will denote it by the actual symbol that is type 2 error which is denoted by beta. And then if it is hypothesis is true test reject. then it will be alpha that is type 1 error and then if it is false and test also reject then we have done a correct decision upon this so you can represent like this so you can see the situation where we will have dangerous error decisions, right? So, what is the dangerous error decision? Is it alpha or is it beta? Ma'am? Yes. Will you please explain alpha is equal to 1 minus meta once again please. Yes. So what is the dangerous error decision here? Beta. Yes. So beta type 2 error where you will accept the null hypothesis is going to give you a very dangerous situation, very dangerous error decision as well. Right? Thank you. So upon these four formulations, we have the type of errors. And after this type of error, we will learn about two-tailed tests or detailed tests. So I will come to that answer let me just conclude for so that we can have two tailed tests and one tailed test which is again an important part of your hypothesis testing. So, whenever we do statistical testing, right, or statistical inference, there are two alternative ways of computing any significance difference, right, or statistical significance of any parameter but whatever you have taken from your population right so this is one tailed and two tailed so these are two alternative ways when you compute the statistical significance of any parameter you have chosen from your data set right now two tailed test. Is appropriate. Whenever the estimated value. Is greater or. Less than. Greater or. Less than. A specified range. Or certain range. Or, we can say. So, which means that suppose there is some test taker, whether that test taker is going to score above or below some specific range or so, right? So, there is a cricket match, whether the batsman is going to hit below or above a specific range or so, right? So there is a cricket match whether the batsman is going to hit below or above a specific range of scores or not, right? So basically this method is used for null hypothesis. When we say two tail test, right? I'll give you more examples for this and the alternate hypothesis is always accepted over null hypothesis so as i said we will start with this assumption of null hypothesis and then the acceptance of alternate hypothesis will be over that null hypothesis once you have rejected that and one tailed test is appropriate whenever you have this like whatever the estimated value you have chosen right upon which you are doing your inference it it deviates or it deviates from the reference value or your actual value only in one direction it could be left or right right i'll give you the curves as well. So, we will learn from the curve. So, one tail test, as I said, is appropriate if the estimated value deviates from reference value only in one direction. So there you can use one tail test. For example, suppose there is a factory where a machine produces, say, more than 1% effective products, right? So, in that situation, we are just concerned about the deviation in one direction only. So, more than 1% only, we are going to look for the significant difference in the population or the sample which we have chosen, right? So, if it is on one side only, if the estimated value exists on the one side of your area or whatever your region is, so it means, and depending upon the direction of interest, whether it is greater than or less than, it could be on both sides, right? It's not always on the positive edge or on the positive side of the curve, right? So we say that this is going to be one-sided test, right? So these are named as one-sided and two-sided test as well or we can call them as one-tailed or two-tailed test. So we'll just see a curve here. So you can see a normal distribution curve. So, you see the mean of the population which is mean of the or we can call this hypothesized mean. So, there are regions of acceptance or rejection and in literature there are standard significance level so we should know the standard significance level as well so the standard significance level could be in literature you will find it could be either five percent or one percent so explicitly you would be given in the problems that calculate the test of significance for 5% or 1%. If it is not given, then understand that whenever you will do calculation upon this significance difference, you have to calculate for 5% by default. So once if you have been given any problem which mentions that calculate this difference or test the hypothesis for 1% significance level then you have to calculate accordingly because these two will make different values as per the standard error table. So we will learn what is the standard error and then we will see the different values for 1% or 5%. So need not to go every time for the table for 1% or 5%. You can just learn the values. So you can learn the value for 1% as 2.58 and for 5% it is 1.96. Now I'll tell you what exactly this 5% or 1% means. Let me just complete this. So this this is your acceptance region and this is your rejection region. So, this is 0.025 and the acceptance region would be this is again here 0.025 and whatever is the region we have we will have 0.475 because in totality this should be 1 as we have already learnt in normal distributions, right? So, plus 5, it would be total 1, 0.5 on each side, right? And then we will divide from 0.5, we will have this acceptance region based upon the significance level. So, if we talk on 1%, right, it would be 2.57, 5.8 and if we talk on 5 So, this curve has been drawn for 5% of significance level. And if we see the standard error table at 0.475, this value is actually mapped from that standard error table. So, this value 1.96, it has come from the table. We have a standard error table. So this value 1.96 it has come from the table. We have a standard error table and if we check this table at 0.475 according to the 5% of significance level we will have these values and this value is going to be 1.96. Similarly if we check for 1% and for 1%, let us see the region's division. It will be 0.495 as the accept. Because now the region of acceptance will be more. And rejection will accordingly be less. So, it will be 0.005 and it will be 0.005. So, again this is your hypothesized mean and these are like hypothesized mean plus 2.58 some standard deviation of the hypothesized mean and again this is Similarly you can represent for this. 5% as well. 2.58. Of your standard deviation. Of hypothesized mean. So basically in the normal distribution. We have already learned that. As soon as we move towards this. Towards infinity. Or towards this range. So it is going to be a standard deviation so there we have learned some values for different regions in the normal curve like for this for this at one two or five questions so we have learned different values we have learned that deviation so this curve is going to be deviate from it or there is a standard deviation from the normalized or the hypothesized mean which is there there at the center, right? Mean, median or more, they will lie on the same line. So whatever deviation from this mean is, is going to decide what is the significance level or what is the difference of significance here, right? That difference you have to calculate. So basically, we said 5% if we say, right, it means possibility of rejection. When we say it is hypothesis testing, it means possibility of rejection of null hypothesis is 5%, right? And if it is 1%, we say possibility of rejection is 1%. So we have these two standard significance level. So we can test or we can say that there is deviation of 1% or 5%. And depending upon the criticality of your application, you can decide what significance level you are going to allow. Either you are going to allow for 1% or 5%. Sometimes your application is very critical right it might be time critical it might be resource critical or it could be based on any parameter it could be a critical application or real world application which has to be based upon real parameter or so so you cannot allow more range of error right so five percent could be a very high range in comparison to one percent so, you can say that I can only allow 1%. So, my acceptance region would be like very high. It has to be near to like the acceptance region only, right? It has to be near to 1%. So, or we can say 0.5 on one side or if it is a one tail test, so it has to be near to 0.5 or if it is a two tail test on both sides, you are going to test either accept or rejects, then you have to see accordingly. But the meaning is that we cannot allow more difference, right? The significance level could not be more. So, as I said, lower is the difference, more is the probability that your hypothesis is going to be accepted and it can be proved correct. So, whatever difference, minimum difference you have depending upon your application you have chosen, you have to decide what significance level I could allow in my sample population testing. That is true. So, we have seen that and as i said this value has come from the table so your standard range will fall in the category of 1. minus 1.96 to for 5 percent we can say it would be minus 1.96 to plus 1.96 so whenever you calculate, whenever you will solve the problems and if that value, that test falls between 1.96 to 1.96, it means your hypothesis will be accepted. And if there is deviation from these values, from this range, it comes out of this range, your rejection region will be located in one tail only, right? Which could be like left or right, depending upon the hypothesis. Because one-tailed, as I said, two-tailed will be mainly used for null hypothesis. And this one-tailed test can be used for the formulation of alternate hypothesis. And it depends upon that hypothesis only. So let me give you another example for one-tailed and two-tailed so that it is more clear. And after that, we will come to some problems based upon this complete theory of test of significance. And we will learn for large samples and small samples. There are different types of tests of significance. There are different tests for attributes. There are different tests for difference between two proportions given in a sample population. Suppose there are two samples which you have drawn. So there then you have to see the difference between these two proportions which you have drawn from your population. For the attributes there would be different tests. For the sample size less than 30 there will be a different test. And for sample size which is more than 30 there would be a different test. So we will come to this. But before that, we have to learn all this theory, which is about your starting with your test of statistical inference, which will have these test of hypothesis. And we'll have null hypothesis and alternate hypothesis. And then we will see the different steps, how to set up a null or the alternate hypothesis. And then the type of errors can have and then the significance level which we can allow in the sample population. So whatever the possibility of rejection is there, so is it 1% or 5% depending upon your application criticality, you can decide what you are going to allow. So a very simple example. Let's take the simple example of tossing coins. So if we say one tail and two tail tests. So we have flipping or tossing a coin so whenever we do coin flipping right so null hypothesis is nothing it's the sequence of your Bernoulli trials and what is the probability when you start with the Bernoulli trials it's the probability 0.5 so it could be either head or it could be either tail right So, 1 is always for head and 0 for the tail. So, what would be the common test statistic? So, in coin flipping we said, this is my problem flipping a coin and the null hypothesis will be sequence of Bernoulli Troils with probability 0.5, right. And this is going to yield a random variable x. This random variable x will be 1 for head and 0 for takes. And the common statistic, the common test statistics is the sample mean here. And sample mean of what? Sample mean of number of heads. Right? You can denote it with any like it could be x bar or so. If it is X, if this random variable is denoted by X, which is generated by the Bernoulli trials. Now, if you are testing for whether this coin is biased towards heads, right, which test would be appropriate. So now I have come to test, right? Test of significance. Now I want to test for whether this coin is biased towards heads, right? It means I am concerned only about heads. It means that I am going to apply a one tailed test. Because only a large number of heads would be significant here. So in that case you can have a data set of five heads, right? For example, if you have a data set of say five heads, which sample mean say one or say x bar is 1 then it will have how many chances of occurring? 1 upon 32 which is 0.03125. Nearly we can say 0.03. So, we can say 5 consecutive flips with two outcomes and then we will calculate and if we calculate the p value which has come out to be 0.03 it would be significant it means if you have again if you have taken your significance level say 0.05 right. It could be 1% or 5% depending. So if you have taken this significance level of testing to be 0.05 for this coin flipping example. It means your hypothesis will be accepted or rejected. Your null hypothesis will be. If at this level I am going to test whether the coin is biased towards heads or tails, then there will be a two-tailed test. Then you will have a two-tailed test. And then again, if you have a data set of 5 head with sample mean 1, you will have 2 by 32. And then you will have this value somewhere. And then you can say that if you are testing it on the same significance level of 0.05. So, we can say that this would have this p-value 0.06 around. And it will not reject the null hypothesis. Right? If you identify or have this p value 0.06 around and it will not reject the null hypothesis. Right? If you identify or have this. So, this is the basic difference between one tail and two tail test. As I said, when we are concerned on the one side only would be positive or negative. So, we are going to apply the one tail test and then we will have two tail test if we are concerned upon both the sides. right? So this is two tailed test and depending upon the significance level, you can decide whether your hypothesis, null hypothesis will be accepted or rejected. So whatever significance level you have chosen to test for. Okay. Thank you.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install optimum","metadata":{"execution":{"iopub.status.busy":"2024-10-12T13:59:17.926844Z","iopub.execute_input":"2024-10-12T13:59:17.927251Z","iopub.status.idle":"2024-10-12T13:59:30.954411Z","shell.execute_reply.started":"2024-10-12T13:59:17.927211Z","shell.execute_reply":"2024-10-12T13:59:30.953366Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: optimum in /opt/conda/lib/python3.10/site-packages (1.23.1)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from optimum) (15.0.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.13.3)\nRequirement already satisfied: transformers>=4.29 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.29->optimum) (4.45.2)\nRequirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from optimum) (2.4.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from optimum) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.26.4)\nRequirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from optimum) (0.25.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum) (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2024.6.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->optimum) (3.1.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum) (12.6.77)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->transformers[sentencepiece]>=4.29->optimum) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->transformers[sentencepiece]>=4.29->optimum) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->transformers[sentencepiece]>=4.29->optimum) (0.20.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.29->optimum) (3.20.3)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.29->optimum) (0.2.0)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.9.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade transformers\n!pip install --upgrade auto-gptq\n!pip install --upgrade optimum\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T14:09:56.158658Z","iopub.execute_input":"2024-10-12T14:09:56.159061Z","iopub.status.idle":"2024-10-12T14:10:35.026956Z","shell.execute_reply.started":"2024-10-12T14:09:56.159023Z","shell.execute_reply":"2024-10-12T14:10:35.025260Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: auto-gptq in /opt/conda/lib/python3.10/site-packages (0.7.1)\nRequirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.34.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (3.0.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.26.4)\nRequirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.0.1)\nRequirement already satisfied: gekko in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.2.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (2.4.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.4.5)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.45.2)\nRequirement already satisfied: peft>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.13.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.66.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.2)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->auto-gptq) (12.6.77)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (0.20.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.9.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq) (1.16.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.26.0->auto-gptq) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: optimum in /opt/conda/lib/python3.10/site-packages (1.23.1)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from optimum) (15.0.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.13.3)\nRequirement already satisfied: transformers>=4.29 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.29->optimum) (4.45.2)\nRequirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from optimum) (2.4.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from optimum) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.26.4)\nRequirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from optimum) (0.25.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum) (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2024.6.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->optimum) (3.1.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum) (12.6.77)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->transformers[sentencepiece]>=4.29->optimum) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->transformers[sentencepiece]>=4.29->optimum) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->transformers[sentencepiece]>=4.29->optimum) (0.20.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.29->optimum) (3.20.3)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.29->optimum) (0.2.0)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.9.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom auto_gptq import AutoGPTQForCausalLM\nimport torch\n\ndef organize_lecture_content(input_file, output_file, max_length=2048):\n    \"\"\"\n    Organizes a lecture transcript into a structured format using a quantized Llama model.\n\n    Parameters:\n    - input_file (str): Path to the input text file containing the lecture transcript.\n    - output_file (str): Path to the output text file where the organized content will be saved.\n    - max_length (int): Maximum number of new tokens to generate in the organized content.\n\n    Returns:\n    - organized_content (str): The organized lecture content.\n    \"\"\"\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    # Define the quantized model ID\n    model_id = \"neuralmagic/Meta-Llama-3-8B-Instruct-quantized.w8a16\"\n    \n    try:\n        # Load tokenizer\n        tokenizer = AutoTokenizer.from_pretrained(model_id)\n        \n        # Load quantized model using from_quantized\n        model = AutoGPTQForCausalLM.from_quantized(\n            model_id,\n            use_safetensors=True,          # Use safetensors if available\n            trust_remote_code=True,        # Only set to True if you trust the model's source\n            device_map=\"auto\",             # Automatically map model to available devices\n        )\n        \n        # Ensure the model is in evaluation mode\n        model.eval()\n        \n    except Exception as e:\n        print(f\"Error loading model or tokenizer: {e}\")\n        return None\n    \n    try:\n        # Read the input lecture transcript\n        with open(input_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n    except Exception as e:\n        print(f\"Error reading input file: {e}\")\n        return None\n    \n    # Define the prompt for organizing the lecture content\n    prompt = f\"\"\"\n    Organize the following lecture transcript into a structured format with these components:\n    1. Introduction: Briefly introduce the main topic.\n    2. Key Concepts: List and explain the main ideas or theories discussed.\n    3. Detailed Explanations: Provide in-depth explanations of each key concept.\n    4. Real-Life Examples: For each concept, provide a practical, real-world example.\n    5. Important Definitions: List crucial terms or definitions introduced.\n    6. Discussion Points: Highlight questions or topics for further discussion.\n    7. Summary: Concisely summarize the main takeaways.\n    8. Further Reading: Suggest resources for additional study.\n\n    Ensure each section is clearly labeled and use bullet points where appropriate. \n    Create a comprehensive, well-organized document that captures the essence of the lecture \n    and makes it easy for students to review and understand the material.\n\n    Lecture transcript to organize:\n    {text}\n\n    Organized lecture content:\n    \"\"\"\n    \n    try:\n        # Tokenize the prompt\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n        \n        # Generate the organized content\n        with torch.no_grad():\n            output = model.generate(\n                **inputs,\n                max_new_tokens=max_length,\n                num_return_sequences=1,\n                temperature=0.7,\n                top_p=0.95,\n                eos_token_id=tokenizer.eos_token_id,  # Ensure proper end of generation\n            )\n        \n        # Decode the output\n        organized_content = tokenizer.decode(output[0], skip_special_tokens=True)\n        \n        # Remove the original prompt from the output\n        organized_content = organized_content.replace(prompt, \"\").strip()\n        \n    except Exception as e:\n        print(f\"Error during model inference: {e}\")\n        return None\n    \n    try:\n        # Save the organized content to the output file\n        with open(output_file, 'w', encoding='utf-8') as file:\n            file.write(organized_content)\n    except Exception as e:\n        print(f\"Error writing to output file: {e}\")\n        return None\n    \n    print(\"Lecture content organized successfully.\")\n    return organized_content\n\n# Example usage\nif __name__ == \"__main__\":\n    input_path = \"/kaggle/input/transcription-1/transcription (3).txt\"    # Replace with your input file path\n    output_path = \"organized_lecture.txt\"   # Replace with your desired output file path\n    organized = organize_lecture_content(input_path, output_path)\n    if organized:\n        print(\"Organized Content:\\n\")\n        print(organized)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T14:11:36.281626Z","iopub.execute_input":"2024-10-12T14:11:36.282048Z","iopub.status.idle":"2024-10-12T14:47:47.229408Z","shell.execute_reply.started":"2024-10-12T14:11:36.282010Z","shell.execute_reply":"2024-10-12T14:47:47.228338Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"WARNING - Exllamav2 kernel is not installed, reset disable_exllamav2 to True. This may because you installed auto_gptq using a pre-build wheel on Windows, in which exllama_kernels are not compiled. To use exllama_kernels to further speedup inference, you can re-install auto_gptq from source.\nWARNING - CUDA kernels for auto_gptq are not installed, this will result in very slow inference speed. This may because:\n1. You disabled CUDA extensions compilation by setting BUILD_CUDA_EXT=0 when install auto_gptq from source.\n2. You are using pytorch without CUDA support.\n3. CUDA and nvcc are not installed in your device.\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nWARNING - ignoring unknown parameter in config.json: batch_size.\nWARNING - ignoring unknown parameter in config.json: block_name_to_quantize.\nWARNING - ignoring unknown parameter in config.json: cache_block_outputs.\nWARNING - ignoring unknown parameter in config.json: dataset.\nWARNING - ignoring unknown parameter in config.json: exllama_config.\nWARNING - ignoring unknown parameter in config.json: max_input_length.\nWARNING - ignoring unknown parameter in config.json: model_seqlen.\nWARNING - ignoring unknown parameter in config.json: module_name_preceding_first_block.\nWARNING - ignoring unknown parameter in config.json: modules_in_block_to_quantize.\nWARNING - ignoring unknown parameter in config.json: pad_token_id.\nWARNING - ignoring unknown parameter in config.json: quant_method.\nWARNING - ignoring unknown parameter in config.json: tokenizer.\nWARNING - ignoring unknown parameter in config.json: use_cuda_fp16.\nWARNING - ignoring unknown parameter in config.json: use_exllama.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/78.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"298599449b194c818420956f349bc969"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f932fb89bf54aada63a72da3c22988b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc9cb592568c4a548b6d7c60df93225d"}},"metadata":{}},{"name":"stderr","text":"INFO - The layer lm_head is not quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/545 [00:00<?, ?w/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/418 [00:00<?, ?w/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\nThis is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (8192). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n","output_type":"stream"},{"name":"stdout","text":"Lecture content organized successfully.\nOrganized Content:\n\n**Introduction**\n     * Statistical inference\n     * Test of significance\n     * Hypothesis testing\n\n     **Key Concepts**\n     * Null hypothesis (H0)\n     * Alternate hypothesis (H1)\n     * Type 1 error (alpha)\n     * Type 2 error (beta)\n     * Significance level (alpha)\n     * One-tailed test\n     * Two-tailed test\n\n     **Detailed Explanations**\n     * Null hypothesis: a quantitative statement about a population\n     * Alternate hypothesis: specifies values that the researcher believes to hold true\n     * Type 1 error: rejecting a true null hypothesis\n     * Type 2 error: failing to reject a false null hypothesis\n     * Significance level: the probability of rejecting a true null hypothesis\n     * One-tailed test: used when the estimated value deviates from the reference value in one direction only\n     * Two-tailed test: used when the estimated value deviates from the reference value in both directions\n\n     **Real-Life Examples**\n     * Coin flipping: testing for bias towards heads or tails\n     * Coaching centers: testing whether extra coaching benefits students\n\n     **Important Definitions**\n     * Statistical inference: the process of drawing conclusions about a population based on a sample\n     * Test of significance: a statistical test used to determine whether a null hypothesis is accepted or rejected\n     * Significance level: the probability of rejecting a true null hypothesis\n\n     **Discussion Points**\n     * Type 1 error: the probability of rejecting a true null hypothesis\n     * Type 2 error: the probability of failing to reject a false null hypothesis\n     * Significance level: the probability of rejecting a true null hypothesis\n\n     **Summary**\n     * Statistical inference: the process of drawing conclusions about a population based on a sample\n     * Test of significance: a statistical test used to determine whether a null hypothesis is accepted or rejected\n     * Significance level: the probability of rejecting a true null hypothesis\n\n     **Further Reading**\n     * Probability theory\n     * Statistical inference\n     * Test of significance\n     * Significance level\n     * Type 1 error\n     * Type 2 error\n     * One-tailed test\n     * Two-tailed test\n     * Coaching centers: testing whether extra coaching benefits students\n     * Coin flipping: testing for bias towards heads or tails\n\n    Note: The lecture transcript is organized into sections for easier reading and understanding. The sections include: Introduction, Key Concepts, Detailed Explanations, Real-Life Examples, Important Definitions, Discussion Points, Summary, and Further Reading. The sections are designed to help students understand the material and to facilitate learning. The sections are designed to help students understand the material and to facilitate learning. The sections are designed to help students understand the material and to facilitate learning. The sections are designed to help students understand the material and to facilitate learning. The sections are designed to help students understand the material and to facilitate learning. The sections are designed to help students understand the material and to facilitate learning. the process of drawing conclusions about a population based on a sample. The sections are designed to help students understand the material and to facilitate learning. The sections are designed to help students understand the material and to facilitate learning. The sections are designed to help students understand the material and to facilitate learning. the process of drawing conclusions about a population based on a sample. The sections are designed to help students understand the material and to facilitate learning. The sections are designed to help students understand the material and to facilitate learning..swing\n    Organized lecture content..swing\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content\n    Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content  Organized lecture content\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade auto-gptq","metadata":{"execution":{"iopub.status.busy":"2024-10-12T14:00:40.429216Z","iopub.execute_input":"2024-10-12T14:00:40.430243Z","iopub.status.idle":"2024-10-12T14:00:53.330849Z","shell.execute_reply.started":"2024-10-12T14:00:40.430196Z","shell.execute_reply":"2024-10-12T14:00:53.329592Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: auto-gptq in /opt/conda/lib/python3.10/site-packages (0.7.1)\nRequirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.34.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (3.0.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.26.4)\nRequirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.0.1)\nRequirement already satisfied: gekko in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.2.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (2.4.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.4.5)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.45.2)\nRequirement already satisfied: peft>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.13.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.66.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.2)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->auto-gptq) (12.6.77)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (0.20.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.9.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq) (1.16.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.26.0->auto-gptq) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install optimum","metadata":{"execution":{"iopub.status.busy":"2024-10-12T13:42:40.299668Z","iopub.execute_input":"2024-10-12T13:42:40.300447Z","iopub.status.idle":"2024-10-12T13:42:55.929857Z","shell.execute_reply.started":"2024-10-12T13:42:40.300400Z","shell.execute_reply":"2024-10-12T13:42:55.928804Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting optimum\n  Downloading optimum-1.23.1-py3-none-any.whl.metadata (20 kB)\nCollecting coloredlogs (from optimum)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.13.3)\nRequirement already satisfied: transformers>=4.29 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.29->optimum) (4.45.1)\nRequirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from optimum) (2.4.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from optimum) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.26.4)\nRequirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from optimum) (0.25.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum) (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2024.6.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->optimum) (3.1.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->transformers[sentencepiece]>=4.29->optimum) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->transformers[sentencepiece]>=4.29->optimum) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->transformers[sentencepiece]>=4.29->optimum) (0.20.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.29->optimum) (3.20.3)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.29->optimum) (0.2.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.9.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\nDownloading optimum-1.23.1-py3-none-any.whl (422 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.6/422.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, optimum\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 optimum-1.23.1\n","output_type":"stream"}]},{"cell_type":"code","source":"input_file = \"/kaggle/input/transcription-1/transcription (3).txt\"\n\noutput_file = \"organized_lecture_content.txt\"\norganized_lecture = organize_lecture_content(input_file, output_file)\nprint(\"Organized lecture content has been generated and saved to\", output_file)\nprint(\"\\nOrganized Content (first 500 characters):\")\nprint(organized_lecture[:500] + \"...\")","metadata":{"execution":{"iopub.status.busy":"2024-10-12T13:56:21.566228Z","iopub.execute_input":"2024-10-12T13:56:21.567186Z","iopub.status.idle":"2024-10-12T13:56:23.301762Z","shell.execute_reply.started":"2024-10-12T13:56:21.567142Z","shell.execute_reply":"2024-10-12T13:56:23.300292Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f787f196f0cf420a93cc45f20cd1da59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb91a1a69bc34067a579e87d0f9f0834"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81634de2aca04c19ad2b60d289a95b77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43d68a71ec4c4d6d9bc568abae73f834"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/transcription-1/transcription (3).txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganized_lecture_content.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m organized_lecture \u001b[38;5;241m=\u001b[39m \u001b[43morganize_lecture_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrganized lecture content has been generated and saved to\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_file)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOrganized Content (first 500 characters):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[35], line 11\u001b[0m, in \u001b[0;36morganize_lecture_content\u001b[0;34m(input_file, output_file, max_length)\u001b[0m\n\u001b[1;32m      8\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneuralmagic/Meta-Llama-3-8B-Instruct-quantized.w8a16\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     14\u001b[0m     text \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3452\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3449\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3452\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\n\u001b[1;32m   3454\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3455\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[1;32m   3456\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/quantizers/quantizer_gptq.py:52\u001b[0m, in \u001b[0;36mGptqHfQuantizer.validate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_environment\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 52\u001b[0m     gptq_supports_cpu \u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto-gptq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.4.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gptq_supports_cpu \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU is required to quantize or run quantize model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/importlib/metadata/__init__.py:996\u001b[0m, in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m(distribution_name):\n\u001b[1;32m    990\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \n\u001b[1;32m    992\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;124;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;124;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mversion\n","File \u001b[0;32m/opt/conda/lib/python3.10/importlib/metadata/__init__.py:969\u001b[0m, in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution\u001b[39m(distribution_name):\n\u001b[1;32m    964\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/importlib/metadata/__init__.py:548\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dist\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n","\u001b[0;31mPackageNotFoundError\u001b[0m: No package metadata was found for auto-gptq"],"ename":"PackageNotFoundError","evalue":"No package metadata was found for auto-gptq","output_type":"error"}]},{"cell_type":"code","source":"!pip install --upgrade transformers torch bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-10-12T13:54:42.907034Z","iopub.execute_input":"2024-10-12T13:54:42.907857Z","iopub.status.idle":"2024-10-12T13:54:55.693273Z","shell.execute_reply.started":"2024-10-12T13:54:42.907815Z","shell.execute_reply":"2024-10-12T13:54:55.692149Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.1)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-10-12T13:54:14.096391Z","iopub.execute_input":"2024-10-12T13:54:14.096789Z","iopub.status.idle":"2024-10-12T13:54:26.627575Z","shell.execute_reply.started":"2024-10-12T13:54:14.096753Z","shell.execute_reply":"2024-10-12T13:54:26.626273Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.77)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}